{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "# Set paths relative to this notebook (in notebooks/)\n",
    "# We assume structure: .../readmit30/notebooks (cwd)\n",
    "#                      .../readmit30/scripts/data\n",
    "base_dir = os.path.abspath(os.path.join(os.getcwd(), '..'))\n",
    "print(f'Base dir (readmit30): {base_dir}')\n",
    "os.environ['TRAIN_PATH'] = os.path.join(base_dir, 'scripts', 'data', 'public', 'train.csv')\n",
    "os.environ['DEV_PATH']   = os.path.join(base_dir, 'scripts', 'data', 'public', 'dev.csv')\n",
    "os.environ['TEST_PATH']  = os.path.join(base_dir, 'scripts', 'data', 'public', 'public_test.csv')\n",
    "os.environ['OUT_PATH']   = 'predictions.csv'\n",
    "\n",
    "print('Environment variables set for local execution.')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1",
   "metadata": {
    "id": "0"
   },
   "source": [
    "# Assignment 1 — Colab Workflow (GitHub + Pre-commit + Submission Validation)\n",
    "\n",
    "This notebook teaches the standard workflow used throughout the course:\n",
    "\n",
    "1. Clone your team repo\n",
    "2. Install dependencies\n",
    "3. Install **pre-commit** and enable a hook to strip notebook outputs\n",
    "4. Run this notebook end-to-end\n",
    "5. Validate `predictions.csv`\n",
    "6. Commit + push + tag\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "1",
    "outputId": "da80d319-5df4-4eee-bcfb-fbe64c8ad2b9"
   },
   "outputs": [],
   "source": [
    "# (Colab) show python and system info\n",
    "import sys, platform\n",
    "print(sys.version)\n",
    "print(platform.platform())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3",
   "metadata": {
    "id": "2"
   },
   "source": [
    "## 1) Clone Repo\n",
    "\n",
    "Login to your personal Github account, and make a fork of: https://github.com/TLKline/AIHC-5010-Winter-2026\n",
    "\n",
    "Follow setup directions for working with a PAT in GitHub (30-second guide):\n",
    "\n",
    "* Go to GitHub → Settings\n",
    "* Developer settings\n",
    "* Personal access tokens\n",
    "* Choose:\n",
    "  * Fine-Grained\n",
    "\n",
    "You can clone using HTTPS.\n",
    "\n",
    "Repo HTTPS URL (e.g., `https://github.com/TLKline/AIHC-5010-Winter-2026.git`)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4",
   "metadata": {
    "id": "5"
   },
   "source": [
    "## 2) Install dependencies\n",
    "\n",
    "This installs whatever is in `requirements.txt`.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5",
   "metadata": {
    "id": "6"
   },
   "outputs": [],
   "source": [
    "!pip -q install -r ../requirements.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6",
   "metadata": {
    "id": "99fd509c"
   },
   "source": [
    "#MAINSTART"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7",
   "metadata": {
    "id": "14"
   },
   "source": [
    "# 4) Submission Notebook (Template)\n",
    "\n",
    "Replace the baseline model with your team’s approach."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "15",
    "outputId": "f1f5f6cf-f56e-4b3b-eb8e-a36ea09f8bd2"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "from pathlib import Path\n",
    "\n",
    "TRAIN_PATH = os.environ.get(\"TRAIN_PATH\", \"../scripts/data/public/train.csv\")\n",
    "DEV_PATH   = os.environ.get(\"DEV_PATH\",   \"../scripts/data/public/dev.csv\")\n",
    "TEST_PATH  = os.environ.get(\"TEST_PATH\",  \"../scripts/data/public/public_test.csv\")\n",
    "OUT_PATH   = os.environ.get(\"OUT_PATH\",   \"predictions.csv\")\n",
    "\n",
    "print(\"TRAIN_PATH:\", TRAIN_PATH)\n",
    "print(\"DEV_PATH:\", DEV_PATH)\n",
    "print(\"TEST_PATH:\", TEST_PATH)\n",
    "print(\"OUT_PATH:\", OUT_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9",
   "metadata": {
    "id": "16"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "np.random.seed(42)\n",
    "\n",
    "train = pd.read_csv(TRAIN_PATH)\n",
    "test = pd.read_csv(TEST_PATH)\n",
    "\n",
    "assert \"row_id\" in train.columns and \"readmit30\" in train.columns\n",
    "assert \"row_id\" in test.columns\n",
    "\n",
    "X_train = train.drop(columns=[\"readmit30\"])\n",
    "y_train = train[\"readmit30\"].astype(int)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10",
   "metadata": {},
   "source": [
    "### Exploratory Data Analysis (EDA)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11",
   "metadata": {},
   "outputs": [],
   "source": [
    "display(train.describe())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Target variable (readmit30) counts:\")\n",
    "print(train['readmit30'].value_counts())\n",
    "print(f\"\\nReadmission rate: {train['readmit30'].mean():.2%}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Inspect categorical features\n",
    "from pandas.api.types import is_numeric_dtype\n",
    "cat_cols = [c for c in X_train.columns if not is_numeric_dtype(X_train[c])]\n",
    "for column in cat_cols[:10]: # Showing first 10 for brevity\n",
    "    print(f\"\\nValue counts for column: {column}\")\n",
    "    print(train[column].value_counts().head(5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14",
   "metadata": {},
   "outputs": [],
   "source": [
    "# === Required EDA Tasks (Missingness + Data Quality) ===\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from IPython.display import display, Markdown\n",
    "\n",
    "df = train.copy()\n",
    "target_col = \"readmit30\"\n",
    "\n",
    "# Treat common placeholder missing values as NaN\n",
    "obj_cols = df.select_dtypes(include=[\"object\"]).columns\n",
    "df[obj_cols] = df[obj_cols].replace(\"?\", np.nan)\n",
    "\n",
    "display(Markdown(\"## EDA Tasks (Missingness + Data Quality)\"))\n",
    "\n",
    "# 1) Basic dataset snapshot\n",
    "n_rows, n_cols = df.shape\n",
    "feature_dtypes = df.drop(columns=[target_col]).dtypes\n",
    "num_count = (feature_dtypes.apply(lambda t: pd.api.types.is_numeric_dtype(t))).sum()\n",
    "cat_count = len(feature_dtypes) - num_count\n",
    "readmit_rate = df[target_col].mean()\n",
    "\n",
    "print(f\"Rows x Columns: {n_rows} x {n_cols}\")\n",
    "print(f\"Outcome column: {target_col}\")\n",
    "print(f\"Readmission rate: {readmit_rate:.2%}\")\n",
    "print(f\"Numeric features: {num_count} | Categorical features: {cat_count}\")\n",
    "display(df.head())\n",
    "\n",
    "# 2) Missingness audit\n",
    "missing_tbl = (\n",
    "    df.isna().sum()\n",
    "    .to_frame(\"missing_count\")\n",
    "    .assign(missing_pct=lambda x: x[\"missing_count\"] / len(df) * 100)\n",
    "    .sort_values(\"missing_pct\", ascending=False)\n",
    " )\n",
    "display(Markdown(\"### Missingness table (sorted)\"))\n",
    "display(missing_tbl)\n",
    "\n",
    "top15 = missing_tbl.head(15).iloc[::-1]\n",
    "plt.figure(figsize=(8, 6))\n",
    "plt.barh(top15.index, top15[\"missing_pct\"], color=\"#4C78A8\")\n",
    "plt.title(\"Top 15 Columns by % Missing\")\n",
    "plt.xlabel(\"% Missing\")\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "acceptable_cols = missing_tbl[missing_tbl[\"missing_pct\"] < 5].head(3).index.tolist()\n",
    "problem_cols = missing_tbl[missing_tbl[\"missing_pct\"] > 30].head(3)\n",
    "\n",
    "display(Markdown(\"### Missingness recommendations\"))\n",
    "print(\"Acceptable missingness (<5%):\")\n",
    "for c in acceptable_cols:\n",
    "    print(f\"- {c}\")\n",
    "\n",
    "print(\"\\nProblematic missingness (>30%) and action:\")\n",
    "for c, row in problem_cols.iterrows():\n",
    "    action = \"drop\" if row[\"missing_pct\"] > 50 else \"impute or investigate collection\"\n",
    "    print(f\"- {c}: {row['missing_pct']:.1f}% missing → {action}\")\n",
    "\n",
    "# 3) Is missingness related to the outcome?\n",
    "display(Markdown(\"### Missingness vs Outcome (3 columns)\"))\n",
    "missing_candidates = missing_tbl[missing_tbl[\"missing_pct\"] > 15].index.tolist()\n",
    "missing_candidates = [c for c in missing_candidates if c != target_col]\n",
    "if len(missing_candidates) < 3:\n",
    "    missing_candidates = [c for c in missing_tbl.index if c != target_col and missing_tbl.loc[c, \"missing_pct\"] > 0][:3]\n",
    "if len(missing_candidates) < 3:\n",
    "    missing_candidates = [c for c in missing_tbl.index if c != target_col][:3]\n",
    "\n",
    "missing_assoc_notes = []\n",
    "for col in missing_candidates[:3]:\n",
    "    is_missing = df[col].isna()\n",
    "    rates = df.groupby(is_missing)[target_col].mean().reindex([False, True])\n",
    "    rates.index = [\"Not Missing\", \"Missing\"]\n",
    "    table = rates.to_frame(\"readmit_rate\")\n",
    "    display(Markdown(f\"**{col}**\"))\n",
    "    display(table)\n",
    "\n",
    "    plt.figure(figsize=(4, 3))\n",
    "    plt.bar(table.index, table[\"readmit_rate\"], color=[\"#72B7B2\", \"#F58518\"])\n",
    "    plt.title(f\"Readmit Rate by Missingness: {col}\")\n",
    "    plt.ylabel(\"Readmit Rate\")\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "    diff = abs(table.loc[\"Missing\", \"readmit_rate\"] - table.loc[\"Not Missing\", \"readmit_rate\"])\n",
    "    note = \"associated\" if diff >= 0.03 else \"not strongly associated\"\n",
    "    missing_assoc_notes.append((col, note, diff))\n",
    "    print(f\"Interpretation: Missingness appears {note} with outcome (Δ ≈ {diff:.3f}).\\n\")\n",
    "\n",
    "# 4) Minimal data quality checks\n",
    "display(Markdown(\"### Data quality checks\"))\n",
    "dup_count = df.duplicated().sum()\n",
    "print(f\"Duplicate rows: {dup_count}\")\n",
    "\n",
    "id_cols = [c for c in df.columns if any(k in c.lower() for k in [\"patient\", \"encounter\", \"id\"]) ]\n",
    "id_cols = [c for c in id_cols if c != \"row_id\"]\n",
    "if id_cols:\n",
    "    print(\"Top repeated IDs (first 2 ID-like columns):\")\n",
    "    for col in id_cols[:2]:\n",
    "        print(f\"\\n{col}:\")\n",
    "        print(df[col].value_counts().head(5))\n",
    "else:\n",
    "    print(\"No obvious patient/encounter ID columns detected beyond row_id.\")\n",
    "\n",
    "# Outliers / validity for 3 numeric columns\n",
    "num_cols_all = df.select_dtypes(include=[np.number]).columns.tolist()\n",
    "num_cols_all = [c for c in num_cols_all if c != target_col]\n",
    "num_pick = num_cols_all[:3]\n",
    "if len(num_pick) < 3:\n",
    "    print(\"Not enough numeric columns for outlier check.\")\n",
    "else:\n",
    "    summary_rows = []\n",
    "    for col in num_pick:\n",
    "        p1, p99 = df[col].quantile([0.01, 0.99])\n",
    "        summary_rows.append({\n",
    "            \"column\": col,\n",
    "            \"min\": df[col].min(),\n",
    "            \"median\": df[col].median(),\n",
    "            \"max\": df[col].max(),\n",
    "            \"p1\": p1,\n",
    "            \"p99\": p99,\n",
    "        })\n",
    "    summary_df = pd.DataFrame(summary_rows)\n",
    "    display(Markdown(\"#### Numeric validity summary\"))\n",
    "    display(summary_df)\n",
    "\n",
    "    fig, axes = plt.subplots(1, len(num_pick), figsize=(12, 3))\n",
    "    for ax, col in zip(axes, num_pick):\n",
    "        sns.boxplot(x=df[col], ax=ax, color=\"#A1C9F4\")\n",
    "        ax.set_title(col)\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "# Leakage screen (heuristic)\n",
    "leak_keywords = [\"readmit\", \"discharge\", \"death\", \"mort\", \"post\", \"after\", \"length\", \"los\", \"stay\"]\n",
    "leakage_cols = [c for c in df.columns if c != target_col and any(k in c.lower() for k in leak_keywords)]\n",
    "leakage_cols = leakage_cols[:2]\n",
    "if len(leakage_cols) < 2:\n",
    "    extra = [c for c in df.columns if c != target_col and c not in leakage_cols][:2 - len(leakage_cols)]\n",
    "    leakage_cols.extend(extra)\n",
    "\n",
    "def leakage_reason(col: str) -> str:\n",
    "    lc = col.lower()\n",
    "    if \"readmit\" in lc:\n",
    "        return \"directly references the outcome\"\n",
    "    if \"discharge\" in lc:\n",
    "        return \"may include post-discharge information\"\n",
    "    if \"death\" in lc or \"mort\" in lc:\n",
    "        return \"post-outcome indicator\"\n",
    "    if \"length\" in lc or \"los\" in lc or \"stay\" in lc:\n",
    "        return \"likely reflects length of stay, possibly post-admission\"\n",
    "    if \"post\" in lc or \"after\" in lc:\n",
    "        return \"post-event timing indicator\"\n",
    "    return \"could encode post-encounter information\"\n",
    "\n",
    "display(Markdown(\"### Candidate leakage columns\"))\n",
    "for col in leakage_cols:\n",
    "    print(f\"- {col}: {leakage_reason(col)}\")\n",
    "\n",
    "# Final summary bullets (8–12)\n",
    "top5 = missing_tbl[missing_tbl[\"missing_pct\"] > 0].head(5)\n",
    "if top5.empty:\n",
    "    top5 = missing_tbl.head(5)\n",
    "missing_str = \", \".join([f\"{idx} ({row['missing_pct']:.1f}%)\" for idx, row in top5.iterrows()])\n",
    "assoc_note = \"None found\"\n",
    "if missing_assoc_notes:\n",
    "    assoc_note = f\"{missing_assoc_notes[0][0]} is {missing_assoc_notes[0][1]} (Δ ≈ {missing_assoc_notes[0][2]:.3f}).\"\n",
    "\n",
    "summary_bullets = [\n",
    "    f\"Top 5 missing columns: {missing_str}\",\n",
    "    f\"Overall readmission rate: {readmit_rate:.2%}\",\n",
    "    f\"Missingness-outcome check: {assoc_note}\",\n",
    "    \"Drop or review columns with >30% missingness; prioritize imputation for moderate missingness.\",\n",
    "    \"Use consistent encoding for categorical features and monitor high-cardinality columns.\",\n",
    "    \"Check duplicate rows and repeated IDs prior to modeling.\",\n",
    "    \"Investigate outliers using 1st/99th percentiles before scaling or winsorizing.\",\n",
    "    f\"Leakage candidates to review: {', '.join(leakage_cols)}.\",\n",
    "    \"Next steps: run cross-validation and tune model hyperparameters.\",\n",
    "    \"Next steps: calibrate probabilities if using decision thresholds.\",\n",
    " ]\n",
    "\n",
    "display(Markdown(\"### Final Summary (8–12 bullets)\"))\n",
    "display(Markdown(\"\\n\".join([f\"- {b}\" for b in summary_bullets])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 289
    },
    "id": "17",
    "outputId": "84c16f55-f67c-45b6-b360-036b3f0c2633"
   },
   "outputs": [],
   "source": [
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.feature_selection import SelectPercentile, f_classif\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.svm import SVC\n",
    "# TODO: Add any new imports for your own method here\n",
    "from sklearn.ensemble import HistGradientBoostingClassifier\n",
    "from sklearn.preprocessing import OrdinalEncoder\n",
    "from pandas.api.types import is_numeric_dtype\n",
    "\n",
    "method = 4\n",
    "\n",
    "# Define features to drop (high missingness, low value, or leakage/IDs)\n",
    "features_to_drop = [\n",
    "    \"weight\",\n",
    "    \"payer_code\",\n",
    "    \"medical_specialty\",\n",
    "    \"encounter_id\",\n",
    "    \"patient_nbr\",\n",
    "    \"discharge_disposition_id\",\n",
    "    \"row_id\",\n",
    "    \"readmit30\",\n",
    " ]\n",
    "\n",
    "# Drop them from X_train explicitly\n",
    "X_train = X_train.drop(columns=features_to_drop, errors=\"ignore\")\n",
    "\n",
    "cat_cols = [c for c in X_train.columns if not is_numeric_dtype(X_train[c])]\n",
    "num_cols = [c for c in X_train.columns if is_numeric_dtype(X_train[c])]\n",
    "\n",
    "preprocess = ColumnTransformer(\n",
    "    transformers=[\n",
    "        (\"num\", Pipeline([(\"imputer\", SimpleImputer(strategy=\"median\"))]), num_cols),\n",
    "        (\"cat\", Pipeline([(\"imputer\", SimpleImputer(strategy=\"most_frequent\")),\n",
    "                          (\"onehot\", OneHotEncoder(handle_unknown=\"ignore\"))]), cat_cols),\n",
    "    ],\n",
    ")\n",
    "\n",
    "if method==1:\n",
    "    # Use logistic regression model\n",
    "    clf = Pipeline([\n",
    "        (\"preprocess\", preprocess),\n",
    "        (\"model\", LogisticRegression(max_iter=200)),\n",
    "    ])\n",
    "\n",
    "if method==2:\n",
    "    # Use logistic regression model\n",
    "    clf = Pipeline([\n",
    "        (\"preprocess\", preprocess),\n",
    "        (\"model\", LogisticRegression(max_iter=200,class_weight='balanced')),\n",
    "    ])\n",
    "\n",
    "if method==3:\n",
    "    # Use SVC (i.e. SVM model)\n",
    "    clf = Pipeline(\n",
    "        [\n",
    "            (\"preprocess\", preprocess),\n",
    "            (\"scaler\", StandardScaler(with_mean=False)), # Add StandardScaler here\n",
    "            (\"model\", SVC(gamma=\"auto\",max_iter=1000,probability=True)),\n",
    "        ]\n",
    "    )\n",
    "\n",
    "if method == 4:\n",
    "    # Preprocess for HGB: ordinal-encode categories (HGB needs numeric inputs)\n",
    "    preprocess_hgb = ColumnTransformer(\n",
    "        transformers=[\n",
    "            (\"num\", Pipeline([\n",
    "                (\"imputer\", SimpleImputer(strategy=\"median\")),\n",
    "            ]), num_cols),\n",
    "            (\"cat\", Pipeline([\n",
    "                (\"imputer\", SimpleImputer(strategy=\"most_frequent\")),\n",
    "                (\"ord\", OrdinalEncoder(handle_unknown=\"use_encoded_value\", unknown_value=-1)),\n",
    "            ]), cat_cols),\n",
    "        ],\n",
    "        remainder=\"drop\",\n",
    "    )\n",
    "\n",
    "    clf = Pipeline([\n",
    "        (\"preprocess\", preprocess_hgb),\n",
    "        (\"model\", HistGradientBoostingClassifier(\n",
    "            max_depth=6,\n",
    "            learning_rate=0.05,\n",
    "            max_iter=300,\n",
    "            l2_regularization=1.0,\n",
    "            early_stopping=True,\n",
    "            random_state=42,\n",
    "            class_weight='balanced',\n",
    "        )),\n",
    "    ])\n",
    "\n",
    "clf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 206
    },
    "id": "18",
    "outputId": "7e831e34-7b9f-4afe-bdca-f3e14c2c956e"
   },
   "outputs": [],
   "source": [
    "p_test = clf.predict_proba(test)[:, 1]\n",
    "pred = pd.DataFrame({\"row_id\": test[\"row_id\"].astype(int), \"prob_readmit30\": p_test.astype(float)})\n",
    "pred.to_csv(OUT_PATH, index=False)\n",
    "pred.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "19",
    "outputId": "93e4b6e3-2ea2-475b-ef34-6e3213b09bc4"
   },
   "outputs": [],
   "source": [
    "# Validate output format (required for students before tagging)\n",
    "!python ../scripts/validate_submission.py --pred {OUT_PATH} --test {TEST_PATH}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "7a8a4572",
    "outputId": "f510a142-f726-4392-e332-e82c10fadd31"
   },
   "outputs": [],
   "source": [
    "# Calculate metrics for the dev set\n",
    "from sklearn.metrics import roc_auc_score, average_precision_score, brier_score_loss\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "dev = pd.read_csv(DEV_PATH)\n",
    "print('DEV_PATH:', DEV_PATH)\n",
    "print(dev['readmit30'].value_counts())\n",
    "\n",
    "X_dev = dev.drop(columns=[\"readmit30\"])\n",
    "y_dev = dev[\"readmit30\"].astype(int)\n",
    "\n",
    "# Calculate metrics\n",
    "y_true = y_dev.astype(int)\n",
    "y_pred = clf.predict_proba(X_dev)[:, 1]\n",
    "\n",
    "auroc = roc_auc_score(y_true, y_pred)\n",
    "auprc = average_precision_score(y_true, y_pred)\n",
    "brier = brier_score_loss(y_true, y_pred)\n",
    "\n",
    "print(f'AUROC: {auroc:.4f}')\n",
    "print(f'AUPRC: {auprc:.4f}')\n",
    "print(f'Brier Score: {brier:.4f}')\n",
    "\n",
    "# Create figures\n",
    "plt.figure(figsize=(10, 6))\n",
    "\n",
    "# Histogram of predicted probabilities\n",
    "plt.hist(y_pred, bins=20, alpha=0.7, label='Predicted Probabilities')\n",
    "plt.title('Histogram of Predicted Probabilities')\n",
    "plt.xlabel('Probability')\n",
    "plt.ylabel('Frequency')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "# Scatter plot of true vs predicted\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.scatter(y_true, y_pred, alpha=0.5, label='True vs Predicted')\n",
    "plt.title('True vs Predicted Probabilities')\n",
    "plt.xlabel('True Labels')\n",
    "plt.ylabel('Predicted Probabilities')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "# Create ROC Curve\n",
    "from sklearn.metrics import roc_curve\n",
    "\n",
    "fpr, tpr, _ = roc_curve(y_true, y_pred)\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(fpr, tpr, label=f'AUROC = {auroc:.4f}')\n",
    "plt.plot([0, 1], [0, 1], linestyle='--', color='gray')\n",
    "plt.title('ROC Curve')\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "# Create Precision-Recall Curve\n",
    "from sklearn.metrics import precision_recall_curve\n",
    "\n",
    "precision, recall, _ = precision_recall_curve(y_true, y_pred)\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(recall, precision, label=f'AUPRC = {auprc:.4f}')\n",
    "plt.title('Precision-Recall Curve')\n",
    "plt.xlabel('Recall')\n",
    "plt.ylabel('Precision')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "# Create Confusion Matrix Heatmap\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import seaborn as sns\n",
    "\n",
    "threshold = 0.5  # Default threshold for binary classification\n",
    "y_pred_binary = (y_pred >= threshold).astype(int)\n",
    "cm = confusion_matrix(y_true, y_pred_binary)\n",
    "\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', xticklabels=['No Readmit', 'Readmit'], yticklabels=['No Readmit', 'Readmit'])\n",
    "plt.title('Confusion Matrix')\n",
    "plt.xlabel('Predicted Label')\n",
    "plt.ylabel('True Label')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19",
   "metadata": {
    "id": "d42abe98"
   },
   "source": [
    "#MAINEND"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20",
   "metadata": {
    "id": "20"
   },
   "source": [
    "## 5) Validate the predictions file format\n",
    "\n",
    "This checks:\n",
    "- required columns\n",
    "- probabilities in [0, 1]\n",
    "- row_ids match the test file\n",
    "\n",
    "It assumes the submission notebook wrote `predictions.csv` in the repo root.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "21",
    "outputId": "0e0aa0a1-6839-4eb4-9c7f-0dfe8760e13c"
   },
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "pred_path = Path(\"predictions.csv\")\n",
    "test_path = Path(\"../scripts/data/public/public_test.csv\")\n",
    "\n",
    "if not pred_path.exists():\n",
    "    print(\"predictions.csv not found. Run notebooks/submission.ipynb first.\")\n",
    "else:\n",
    "    !python ../scripts/validate_submission.py --pred predictions.csv --test ../scripts/data/public/public_test.csv\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22",
   "metadata": {
    "id": "22"
   },
   "source": [
    "## 6) Commit + push + tag\n",
    "\n",
    "You will:\n",
    "- add changes\n",
    "- commit (pre-commit hook runs here)\n",
    "- push\n",
    "- tag a milestone (example: `milestone_wk3`) and push tags\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23",
   "metadata": {
    "id": "xQucvfTCla8Z"
   },
   "source": [
    "You will need a Personal Access Token (PAT) for the following step. See instructions above."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24",
   "metadata": {
    "id": "26"
   },
   "source": [
    "## Done ✅\n",
    "\n",
    "If you hit issues:\n",
    "- Make sure you pulled the latest course template (missing files).\n",
    "- Make sure `data/public/*` exists in your repo (or your instructor provided it separately).\n"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.14.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
