{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0",
   "metadata": {},
   "source": [
    "# Assignment 1 EDA\n",
    "\n",
    "Exploratory data analysis for the readmit30 dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Environment setup for local execution\n",
    "import os\n",
    "import sys\n",
    "\n",
    "base_dir = os.path.abspath(os.path.join(os.getcwd(), '..'))\n",
    "\n",
    "os.environ['TRAIN_PATH'] = os.path.join(base_dir, 'scripts', 'data', 'public', 'train.csv')\n",
    "os.environ['DEV_PATH']   = os.path.join(base_dir, 'scripts', 'data', 'public', 'dev.csv')\n",
    "os.environ['TEST_PATH']  = os.path.join(base_dir, 'scripts', 'data', 'public', 'public_test.csv')\n",
    "os.environ['OUT_PATH']   = 'predictions.csv'\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load data\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from IPython.display import display, Markdown\n",
    "\n",
    "np.random.seed(42)\n",
    "\n",
    "TRAIN_PATH = os.environ.get(\"TRAIN_PATH\", \"../scripts/data/public/train.csv\")\n",
    "DEV_PATH   = os.environ.get(\"DEV_PATH\",   \"../scripts/data/public/dev.csv\")\n",
    "TEST_PATH  = os.environ.get(\"TEST_PATH\",  \"../scripts/data/public/public_test.csv\")\n",
    "OUT_PATH   = os.environ.get(\"OUT_PATH\",   \"predictions.csv\")\n",
    "\n",
    "train = pd.read_csv(TRAIN_PATH)\n",
    "test = pd.read_csv(TEST_PATH)\n",
    "\n",
    "assert \"row_id\" in train.columns and \"readmit30\" in train.columns\n",
    "assert \"row_id\" in test.columns\n",
    "\n",
    "X_train = train.drop(columns=[\"readmit30\"])\n",
    "y_train = train[\"readmit30\"].astype(int)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3",
   "metadata": {},
   "source": [
    "---\n",
    "## 1. Data Snapshot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = train.copy()\n",
    "target_col = \"readmit30\"\n",
    "\n",
    "# Treat common placeholder missing values as NaN\n",
    "obj_cols = df.select_dtypes(include=[\"str\"]).columns\n",
    "df[obj_cols] = df[obj_cols].replace(\"?\", np.nan)\n",
    "\n",
    "# Basic dataset snapshot\n",
    "n_rows, n_cols = df.shape\n",
    "feature_dtypes = df.drop(columns=[target_col]).dtypes\n",
    "num_count = feature_dtypes.apply(lambda t: pd.api.types.is_numeric_dtype(t)).sum()\n",
    "cat_count = len(feature_dtypes) - num_count\n",
    "readmit_rate = df[target_col].mean()\n",
    "\n",
    "print(f\"Rows x Columns: {n_rows:,} x {n_cols}\")\n",
    "print(f\"Outcome column: {target_col}\")\n",
    "print(f\"Readmission rate: {readmit_rate:.2%}\")\n",
    "print(f\"Numeric features: {num_count} | Categorical features: {cat_count}\")\n",
    "print(f\"\\nTarget distribution:\")\n",
    "print(df[target_col].value_counts())\n",
    "display(df.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5",
   "metadata": {},
   "source": [
    "---\n",
    "## 2. Missingness Audit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate missingness for all columns\n",
    "missing_tbl = (\n",
    "    df.isna().sum()\n",
    "    .to_frame(\"missing_count\")\n",
    "    .assign(missing_pct=lambda x: x[\"missing_count\"] / len(df) * 100)\n",
    "    .sort_values(\"missing_pct\", ascending=False)\n",
    ")\n",
    "\n",
    "display(Markdown(\"### Missingness Table (Top 20 by %)\"))\n",
    "display(missing_tbl.head(20))\n",
    "\n",
    "# top 15 columns by % missing\n",
    "top15 = missing_tbl.head(15).iloc[::-1]\n",
    "plt.figure(figsize=(10, 7))\n",
    "plt.barh(top15.index, top15[\"missing_pct\"], color=\"#4C78A8\")\n",
    "plt.title(\"Top 15 Columns by % Missing\", fontsize=14, fontweight='bold')\n",
    "plt.xlabel(\"% Missing\")\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# look at columns by missingness level\n",
    "acceptable_cols = missing_tbl[missing_tbl[\"missing_pct\"] < 5].head(10).index.tolist()\n",
    "problem_cols = missing_tbl[missing_tbl[\"missing_pct\"] > 30].head(5).index.tolist()\n",
    "\n",
    "print(\"\\nColumns with low missingness (<5%):\")\n",
    "for c in acceptable_cols:\n",
    "    pct = missing_tbl.loc[c, \"missing_pct\"]\n",
    "    print(f\"  {c}: {pct:.2f}%\")\n",
    "\n",
    "print(\"\\nColumns with high missingness (>30%):\")\n",
    "for c in problem_cols:\n",
    "    pct = missing_tbl.loc[c, \"missing_pct\"]\n",
    "    print(f\"  {c}: {pct:.2f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7",
   "metadata": {},
   "source": [
    "---\n",
    "## 3. Missingness vs Outcome"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8",
   "metadata": {},
   "outputs": [],
   "source": [
    "display(Markdown(\"### Missingness vs Outcome Analysis\"))\n",
    "\n",
    "# Select 3 columns with interesting missingness patterns\n",
    "missing_candidates = ['weight', 'A1Cresult', 'payer_code']\n",
    "\n",
    "# Ensure columns exist\n",
    "missing_candidates = [c for c in missing_candidates if c in df.columns]\n",
    "\n",
    "missing_assoc_notes = []\n",
    "readmit_table_rows = []\n",
    "\n",
    "for col in missing_candidates:\n",
    "    is_missing = df[col].isna()\n",
    "    rates = df.groupby(is_missing)[target_col].mean().reindex([False, True])\n",
    "    rates.index = [\"Not Missing\", \"Missing\"]\n",
    "    table = rates.to_frame(\"readmit_rate\")\n",
    "    \n",
    "    display(Markdown(f\"#### **{col}** (Missing: {missing_tbl.loc[col, 'missing_pct']:.1f}%)\"))\n",
    "    display(table)\n",
    "    \n",
    "    # plot\n",
    "    plt.figure(figsize=(5, 3.5))\n",
    "    plt.bar(table.index, table[\"readmit_rate\"], color=[\"#72B7B2\", \"#F58518\"])\n",
    "    plt.title(f\"Readmit Rate by Missingness: {col}\")\n",
    "    plt.ylabel(\"Readmit Rate\")\n",
    "    plt.ylim(0, max(table[\"readmit_rate\"]) * 1.2)\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    # calculate difference\n",
    "    rate_not_missing = table.loc[\"Not Missing\", \"readmit_rate\"]\n",
    "    rate_missing = table.loc[\"Missing\", \"readmit_rate\"]\n",
    "    diff = abs(rate_missing - rate_not_missing)\n",
    "    \n",
    "    print(f\"\\nReadmit rate when missing: {rate_missing:.2%} vs not missing: {rate_not_missing:.2%}\")\n",
    "    if diff >= 0.02:\n",
    "        print(f\"Missingness appears associated with outcome (diff = {diff:.2%}). Consider MAR/MNAR.\\n\")\n",
    "    else:\n",
    "        print(f\"Missingness not strongly associated (diff = {diff:.2%}). Likely MCAR.\\n\")\n",
    "    \n",
    "    readmit_table_rows.append({\n",
    "        \"variable\": col,\n",
    "        \"not_missing_rate_%\": rate_not_missing * 100,\n",
    "        \"missing_rate_%\": rate_missing * 100,\n",
    "        \"difference_%\": diff * 100\n",
    "    })\n",
    "\n",
    "# Summary table (TH's format)\n",
    "# summary table\n",
    "readmit_comparison = pd.DataFrame(readmit_table_rows).round(2)\n",
    "display(readmit_comparison)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9",
   "metadata": {},
   "source": [
    "---\n",
    "## 4. Data Quality Checks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10",
   "metadata": {},
   "outputs": [],
   "source": [
    "display(Markdown(\"### Duplicate Checks\"))\n",
    "\n",
    "# check duplicates\n",
    "dup_rows = df.duplicated(keep='first').sum()\n",
    "print(f\"Duplicate rows (excluding first occurrence): {dup_rows:,}\")\n",
    "\n",
    "# Check for repeated encounter IDs\n",
    "if 'encounter_id' in df.columns:\n",
    "    dup_encounters = df.duplicated(subset=['encounter_id'], keep='first').sum()\n",
    "    print(f\"Duplicate encounter_ids: {dup_encounters:,}\")\n",
    "\n",
    "# Check for repeated patient numbers\n",
    "if 'patient_nbr' in df.columns:\n",
    "    dup_patients = df.duplicated(subset=['patient_nbr'], keep='first').sum()\n",
    "    print(f\"Duplicate patient_nbr's: {dup_patients:,}\")\n",
    "    print(f\"\\nTop 10 repeated patient_nbr's:\")\n",
    "    print(df['patient_nbr'].value_counts().head(10))\n",
    "    print(f\"\\nInterpretation: {dup_patients:,} patients have multiple encounters in the training set.\")\n",
    "    print(\"Risk: Model may see test-set data if same patients appear in train/test splits.\")\n",
    "    print(\"Recommendation: Verify train/test split is done at patient level, not encounter level.\")\n",
    "\n",
    "display(Markdown(\"### Numeric Outlier Analysis\"))\n",
    "\n",
    "# Select 3 key numeric columns for outlier analysis\n",
    "outlier_cols = [\"time_in_hospital\", \"num_lab_procedures\", \"num_medications\"]\n",
    "outlier_cols = [c for c in outlier_cols if c in df.columns]\n",
    "\n",
    "if len(outlier_cols) >= 3:\n",
    "    # percentile-based summary\n",
    "    summary_rows = []\n",
    "    for col in outlier_cols:\n",
    "        p1, p99 = df[col].quantile([0.01, 0.99])\n",
    "        summary_rows.append({\n",
    "            \"column\": col,\n",
    "            \"min\": df[col].min(),\n",
    "            \"p01\": p1,\n",
    "            \"median\": df[col].median(),\n",
    "            \"p99\": p99,\n",
    "            \"max\": df[col].max()\n",
    "        })\n",
    "    summary_df = pd.DataFrame(summary_rows)\n",
    "    display(Markdown(\"#### Percentile Summary (1st/50th/99th)\"))\n",
    "    display(summary_df)\n",
    "    \n",
    "    # histograms\n",
    "    fig, axes = plt.subplots(1, len(outlier_cols), figsize=(15, 4))\n",
    "    for ax, col in zip(axes, outlier_cols):\n",
    "        data = df[col].dropna()\n",
    "        ax.hist(data, bins=30, color=\"#4C78A8\", edgecolor=\"white\", alpha=0.9)\n",
    "        ax.set_title(f\"{col}\")\n",
    "        ax.set_xlabel(col)\n",
    "        ax.set_ylabel(\"Count\")\n",
    "    fig.suptitle(\"Distributions: Numeric Features\", y=1.02, fontsize=14, fontweight='bold')\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    # boxplots\n",
    "    fig, axes = plt.subplots(1, len(outlier_cols), figsize=(12, 3))\n",
    "    for ax, col in zip(axes, outlier_cols):\n",
    "        sns.boxplot(x=df[col], ax=ax, color=\"#A1C9F4\")\n",
    "        ax.set_title(col)\n",
    "    fig.suptitle(\"Boxplots: Outlier Detection\", y=1.02, fontsize=14, fontweight='bold')\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    print(\"\\nInterpretation:\")\n",
    "    print(\"   - Check for extreme outliers (values beyond 99th percentile)\")\n",
    "    print(\"   - Consider winsorizing or capping at 1st/99th percentiles before scaling\")\n",
    "    print(\"   - Validate that extreme values are clinically plausible (not data entry errors)\")\n",
    "else:\n",
    "    print(\"Not enough numeric columns for comprehensive outlier analysis.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11",
   "metadata": {},
   "source": [
    "---\n",
    "## 5. Leakage Screening"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12",
   "metadata": {},
   "outputs": [],
   "source": [
    "display(Markdown(\"### Leakage Screening\"))\n",
    "\n",
    "# keyword-based screening\n",
    "leak_keywords = [\"readmit\", \"discharge\", \"death\", \"mort\", \"post\", \"after\", \"length\", \"los\", \"stay\"]\n",
    "leakage_cols = [c for c in df.columns if c != target_col and any(k in c.lower() for k in leak_keywords)]\n",
    "\n",
    "# Add known leakage columns from team insights\n",
    "additional_suspects = ['payer_code', 'discharge_disposition_id']\n",
    "for col in additional_suspects:\n",
    "    if col in df.columns and col not in leakage_cols:\n",
    "        leakage_cols.append(col)\n",
    "\n",
    "def leakage_reason(col: str) -> str:\n",
    "    \"\"\"automated reasoning function\"\"\"\n",
    "    lc = col.lower()\n",
    "    if \"readmit\" in lc:\n",
    "        return \"CRITICAL: Directly references the outcome variable\"\n",
    "    if \"discharge\" in lc and \"disposition\" in lc:\n",
    "        return \"HIGH RISK: Discharge disposition known only AFTER admission ends; may indicate deceased/transferred\"\n",
    "    if \"discharge\" in lc:\n",
    "        return \"HIGH RISK: May include post-discharge information\"\n",
    "    if \"death\" in lc or \"mort\" in lc:\n",
    "        return \"CRITICAL: Post-outcome indicator (deceased patients cannot be readmitted)\"\n",
    "    if \"payer\" in lc or \"insurance\" in lc:\n",
    "        return \"MODERATE RISK: Insurance/payer info finalized AFTER discharge; temporal leakage possible\"\n",
    "    if \"length\" in lc or \"los\" in lc or \"stay\" in lc:\n",
    "        return \"MODERATE RISK: Length of stay determined DURING/AFTER admission; may correlate with discharge timing\"\n",
    "    if \"post\" in lc or \"after\" in lc:\n",
    "        return \"HIGH RISK: Post-event timing indicator\"\n",
    "    return \"REVIEW: Could encode post-encounter information\"\n",
    "\n",
    "print(f\"Found {len(leakage_cols)} potential leakage columns:\\n\")\n",
    "for col in leakage_cols[:10]:  # Show first 10\n",
    "    reason = leakage_reason(col)\n",
    "    print(f\"  - {col}\")\n",
    "    print(f\"    {reason}\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13",
   "metadata": {},
   "source": [
    "---\n",
    "## 6. Final Summary\n",
    "\n",
    "- Top 5 missing columns: weight (96.9%), max_glu_serum (94.7%), A1Cresult (83.4%), medical_specialty (48.9%), payer_code (39.6%)\n",
    "- Overall readmission rate: 10.87%\n",
    "- A1Cresult missingness associated with outcome (11.45% missing vs 9.73% not missing) - encode as 'not_measured' indicator\n",
    "- Weight not strongly associated with outcome (diff < 1%) but 97% missing - drop it\n",
    "- Payer_code weak association (11.53% vs 10.92%) but temporal leakage concern - drop it\n",
    "- No duplicate rows found, but multiple encounters per patient - verify patient-level split\n",
    "- Outliers in time_in_hospital, num_lab_procedures, num_medications - consider capping at 1st/99th percentiles\n",
    "- discharge_disposition_id is post-discharge info (home/SNF/expired) - drop to avoid leakage\n",
    "\n",
    "**Next steps:**\n",
    "- Drop: weight, max_glu_serum (too sparse), discharge_disposition_id and payer_code (leakage risk)\n",
    "- Keep A1Cresult but encode missingness as binary indicator\n",
    "- Impute remaining missing with median (numeric) or mode (categorical)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.14.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
